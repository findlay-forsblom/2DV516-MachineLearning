import pandas as pdimport numpy as npfrom matplotlib import pyplot as pltfrom knnRegressor import KNeighborsRegressordataset = pd.read_csv('polynomial200.csv')Xtrain = dataset.iloc[:100].valuesXtest = dataset.iloc[100:].valuesxtest = Xtest[:,0]ytest = Xtest[:,1]fig, ax = plt.subplots(nrows=1, ncols=2)ax[0].scatter(Xtrain[:, 0], Xtrain[:, 1], color='green', label = 'Training set')ax[1].scatter(Xtest[:, 0], Xtest[:, 1], color='blue', label='Test set')fig.legend()plt.tight_layout()x_min, x_max = Xtrain[:, 0].min(), Xtrain[:, 0].max()xx = np.arange(x_min, x_max, 0.02)count = 0ks = [1,3,5,7]fig1, ax2 = plt.subplots(nrows=2, ncols=2)for row in ax2:    for col in row:        regressor = KNeighborsRegressor(ks[count])        regressor.fit(Xtrain[:,0], Xtrain[:,1])        ypred = regressor.predict(xx)        errors = regressor.getTraningerrors()        col.plot(xx,ypred, color= 'green')        col.scatter(Xtrain[:, 0], Xtrain[:, 1], color= 'blue')        col.set_title(f'k = {ks[count]}, MSE = {errors} ')        count +=1plt.tight_layout()#Task 4#x_min, x_max = Xtest[:, 0].min(), Xtest[:, 0].max()#xtest = np.arange(x_min, x_max, 0.02)testks = []mse = []for k in range(1, 14, 2):    regressor = KNeighborsRegressor(k)    regressor.fit(Xtrain[:,0], Xtrain[:,1])    ypred = regressor.predict(xtest)        sums = (ypred - ytest) ** 2    sums = round((np.sum(sums)) / len(ypred), 2)        testks.append(k)    mse.append(sums)    #Task 5mse = np.array(mse)    posmin = mse.argmin()fig3, ax3 = plt.subplots()err = ax3.plot(testks, mse, label= 'MSE values ')best = ax3.scatter(testks[posmin], mse[posmin], color = 'red', label= 'best k')ax3.legend()ax3.set_xlabel('k')ax3.set_ylabel('MSE value')ax3.set_title('MSE test error with different k')print(f'k = {testks[posmin]} gives the best regression since it is the one that produces the least mse error as can be seen in figure 3')plt.show()